---
title: Market Basket Analysis Walkthrough
---
Market Basket Analysis, aka affinity analysis aka association rules mining is an unsupervised machine learning technique which applies an algorithm (apriori algorithm) to identify association rules in datasets.

We'll be applying this algorithm to identify associations in a dataset containing information about cases of perforative acute otitis media in children.

We'll start with loading in our packages

```{r}
library(tidyverse)
library(knitr)
library(ggplot2)
library(lubridate)
library(arules)
library(arulesViz)
library(plyr)
library(RColorBrewer)
library(plotly)
```

And our dataset

```{r}
nepal.gps = read.csv("nepal_gps.csv")

pcv10_serotypes <- c('1', '4', '5', '6B', '7F', '9V', '14', '18C', '19F', '23F') 
pcv13_serotypes <- c('3', '6A', '19A')
pcv15_serotypes <- c('22F', '33F')
pcv20_serotypes <- c('8', '10A', '11A', '12F', '15B')
untypable = c("ALTERNATIVE_ALIB_NT","COVERAGE TOO LOW", "SWISS_NT", "UNTYPABLE")

nepal.gps$Serotype_Group <- ifelse(nepal.gps$In_silico_serotype %in% pcv10_serotypes, "PCV10 Serotypes",
                            ifelse(nepal.gps$In_silico_serotype %in% pcv13_serotypes, "PCV20 Serotypes",
                            ifelse(nepal.gps$In_silico_serotype %in% pcv15_serotypes, "Other PCV Serotypes",
                            ifelse(nepal.gps$In_silico_serotype %in% pcv20_serotypes, "Other PCV Serotypes",
                            ifelse(nepal.gps$In_silico_serotype %in% untypable, "UNTYPABLE",
                            "Non-PCV Serotypes")))))
age_0_2 <- c('1', '2') 
age_3_5 <- c('3', '4', '5')
age_6_up <- c('6', '7', '8', '9', '10', '11', '12', '13', '14')
nepal.gps$Age_years <- ifelse(nepal.gps$Age_years %in% age_0_2, "Age 0-2",
                       ifelse(nepal.gps$Age_years %in% age_3_5, "Age 3-5",
                       ifelse(nepal.gps$Age_years %in% age_6_up, "Age 6-14",
                       "No Age Data")))

nepal.gps <- nepal.gps[nepal.gps$Serotype_Group != "UNTYPABLE", ]

nepal.gps$Vaccine_period <- ifelse(nepal.gps$Vaccine_period == "PREPCV", "Pre-PCV10", "Post-PCV10")

nepal.gps <- nepal.gps %>%
  mutate(Clinical_manifestation = case_when(
    Clinical_manifestation == "CARRIAGE" ~ "Carriage",
    Clinical_manifestation == "MENINGITIS" ~ "Meningitis",
    Clinical_manifestation == "UNSPECIFIED IPD" ~ "Unspecified IPD",
    TRUE ~ Clinical_manifestation))

nepal.gps <- nepal.gps %>% 
  select(Age_years, Clinical_manifestation, Vaccine_period, Serotype_Group)

write.csv(nepal.gps, "nepal.gps.csv", row.names = FALSE)
```


```{r}
tr<-read.transactions("nepal.gps.csv", format= 'basket', sep= ',')
```

```{r}
print('Description of the transactions')
summary(tr)
```

Let's see what items occur most frequently:

```{r}
itemFrequencyPlot(tr,topN=25,type="absolute",col=brewer.pal(8,'Pastel2'), main="Nepal_gps rules")
```
a relative frequency plot
 
```{r}
itemFrequencyPlot(tr,topN=20,type="relative",col=brewer.pal(8,'Pastel2'),main="Relative frequency, Nepal_GPS")
```
## Create some rules

We use the Apriori algorithm from the arules package to look for itemsets and find support for rules

We pass supp=0.0001 and conf=0.8 to return all the rules have a support of at least 0.1% and confidence of at least 80%. 

We sort the rules by decreasing confidence. 

Here are the rules matching these criteria:

```{r}
rules <- apriori(tr, parameter = list(supp=0.01, conf=0.8))
rules <- sort(rules, by='confidence', decreasing = TRUE)
summary(rules)
```


We have 4093 rules, most are 4 or 5 items long. Let's inspect the top 10 rules according to these parameters (supp 0.001, conf =0.8).

```{r}
inspect(rules[1:10])

sorted_rules <- sort(rules, by = "confidence", decreasing = TRUE)

# Inspect the top 10 rules by support
inspect(sorted_rules[1:10])
```

And plot these top 10 rules, or 20, or 50.

```{r}

topRules <- rules[1:10]
plot(rules)
```
now with more colors
```{r}
plot(rules, method = "two-key plot")
```

now how about a network graph?
```{r}
plot(topRules, method="graph")
```
Now let's see an interactive map:
```{r}
plot(topRules, method="graph", engine = 'interactive')
```

```{r}
plot(topRules, method = "grouped")
```

```{r}
p <- plot(topRules, method = "graph", engine = "htmlwidget")

node_labels <- p$x$nodes$label
node_shapes <- p$x$nodes$shape  # "dot" = item, "box" = rule

rule_lift <- quality(topRules)$lift
lhs_items <- LIST(lhs(topRules), decode = TRUE)
rhs_items <- LIST(rhs(topRules), decode = TRUE)

# manual teal gradient
# Replace this part in your original script
rule_teal_colors <- c(
  "#b2d8d8",  # 1.755556
  "#b2d8d8",  # 1.755556
  "#b2d8d8",  # 1.755556
  "#007a7a",  # 2.972326
  "#007c7c",  # 2.918284
  "#8fd1d1",  # 1.370537
  "#85d4d4",  # 1.339656
  "#7bd7d7",  # 1.333718
  "#75d9d9",  # 1.329564
  "#009999"   # 2.743685
)


color_list <- vector("list", length(node_labels))
rule_index <- 1  # Track which rule we're on

for (i in seq_along(node_labels)) {
  if (node_shapes[i] == "box") {
    color_list[[i]] <- list(
      background = "#d3d3d3",
      border = "#aaaaaa",
      highlight = "#d3d3d3"
    )
  } else {
    # Rule node (circle) - assign color by rule index
    color_list[[i]] <- list(
      background = rule_teal_colors[rule_index],
      border = "#00356B",
      highlight = rule_teal_colors[rule_index]
    )
    rule_index <- rule_index + 1
  }
}

p$x$nodes$color <- color_list
p$x$nodes$font <- lapply(seq_len(nrow(p$x$nodes)), function(i) {
  list(color = "#000000", size = 16, face = "bold")
})
p$x$options$nodes <- list(font = list(color = "#000000", size = 16, face = "bold"))
p$x$nodes$size <- rep(25, nrow(p$x$nodes))

p$x$options$physics <- list(
  enabled = TRUE,
  stabilization = list(
    enabled = TRUE,
    iterations = 1000,
    updateInterval = 25,
    onlyDynamicEdges = FALSE,
    fit = TRUE
  ),
  barnesHut = list(
    gravitationalConstant = -2000,
    springLength = 100,
    springConstant = 0.01,
    damping = 0.09
  )
)

p$x$events <- list(
  stabilized = htmlwidgets::JS("
    function () {
      this.physics.disable();
    }
  ")
)

p
```

```{r}
# legend for the above plot
library(ggplot2)

# Your lifts (unique, sorted)
lift_values <- sort(unique(c(
  1.755556,
  2.972326,
  1.396515,
  2.918284,
  1.370537,
  1.342189,
  1.333718,
  1.329564
)))

# Create a data frame for plotting
legend_df <- data.frame(Lift = seq(min(lift_values), max(lift_values), length.out = 100))

# Define a teal gradient palette function from light to dark teal
teal_palette <- colorRampPalette(c("#b2d8d8", "#007a7a"))

ggplot(legend_df, aes(x = Lift, y = 1, fill = Lift)) +
  geom_tile() +
  scale_fill_gradientn(colors = teal_palette(100), breaks = lift_values, labels = round(lift_values, 3)) +
  labs(fill = "Lift") +
  theme_minimal() +
  theme(
    axis.title.y = element_blank(),
    axis.text.y = element_blank(),
    axis.ticks.y = element_blank(),
    axis.text.x = element_text(color = "black", size = 10)
  ) +
  ylab(NULL) +
  xlab("Lift") +
  coord_fixed(ratio = 0.1) +
  theme(panel.grid = element_blank())

```



```{r}
library(arules)
library(arulesViz)
library(scales)

# Step 1: Generate rules
rules <- apriori(tr, parameter = list(supp = 0.01, conf = 0.8))
rules <- sort(rules, by = "confidence", decreasing = TRUE)
topRules <- rules[1:10]

# Step 2: Create interactive plot
p <- plot(topRules, method = "graph", engine = "htmlwidget")

# Step 3: Extract node info
node_labels <- p$x$nodes$label
node_shapes <- p$x$nodes$shape  # "dot" = item, "box" = rule

# Step 4: Get rule lift + itemsets
rule_lift <- quality(topRules)$lift
lhs_items <- LIST(lhs(topRules), decode = TRUE)
rhs_items <- LIST(rhs(topRules), decode = TRUE)

# Step 5: Compute average lift for each item node
get_avg_lift <- function(label) {
  idx_lhs <- which(sapply(lhs_items, function(items) label %in% items))
  idx_rhs <- which(sapply(rhs_items, function(items) label %in% items))
  idx_all <- union(idx_lhs, idx_rhs)
  if (length(idx_all) == 0) return(NA_real_)
  mean(rule_lift[idx_all], na.rm = TRUE)
}

lift_values <- sapply(seq_along(node_labels), function(i) {
  if (node_shapes[i] == "box") return(NA_real_)
  get_avg_lift(node_labels[i])
})

valid_lifts <- lift_values[!is.na(lift_values)]

# Step 6: If no lift values, fallback to default colors
if (length(valid_lifts) == 0) {
  lift_bins <- rep("default", length(lift_values))
} else {
  # Bin into low/medium/high based on tertiles
  tertiles <- quantile(valid_lifts, probs = c(0, 1/3, 2/3, 1), na.rm = TRUE)
  if (length(unique(tertiles)) < 4) {
    tertiles <- seq(min(valid_lifts), max(valid_lifts) + 1e-6, length.out = 4)
  }
  lift_bins <- cut(lift_values,
                   breaks = tertiles,
                   labels = c("low", "medium", "high"),
                   include.lowest = TRUE)
}

# Step 7: Assign colors
color_list <- vector("list", length(node_labels))
for (i in seq_along(node_labels)) {
  if (node_shapes[i] == "box") {
    # Rule = light gray
    color_list[[i]] <- list(
      background = "#d3d3d3",
      border = "#aaaaaa",
      highlight = "#d3d3d3"
    )
  } else {
    # Item = teal by lift bin or fallback
    lift_level <- as.character(lift_bins[i])
    color <- switch(lift_level,
                    "low"     = "#99d3d3",
                    "medium"  = "#33a1a1",
                    "high"    = "#008080",
                    "default" = "#99d3d3",   # fallback color
                    "#cccccc")
    color_list[[i]] <- list(
      background = color,
      border = "#00356B",
      highlight = color
    )
  }
}

# Step 8: Apply styles
p$x$nodes$color <- color_list
p$x$nodes$font <- lapply(seq_len(nrow(p$x$nodes)), function(i) {
  list(color = "#000000", size = 16, face = "bold")
})
p$x$options$nodes <- list(
  font = list(color = "#000000", size = 16, face = "bold")
)
p$x$nodes$size <- rep(25, nrow(p$x$nodes))

# Step 9: Show plot
p
```



now a matrix plot
```{r}
plot(topRules, method = "matrix", engine = "3d", measure = "lift")
```

moving back a bit, let's check a different set of rules:

```{r}
rules_b <- apriori(tr, parameter = list(supp=0.01, conf=0.8))
rules_b <- sort(rules_b, by='confidence', decreasing = TRUE)
summary(rules_b)
```
these more stringent criteria mean that we're down to 115 rules to sort through.
```{r}
sorted_rules <- sort(rules_b, by = "support", decreasing = TRUE)

# Inspect the top 10 rules by support
inspect(sorted_rules[1:10])
```

try to look for only for rules associated with Carriage

```{r}
pneumo.rules<-sort(subset(rules_b, subset = rhs %in% "CARRIAGE"))

inspect(pneumo.rules[1:7])
```
now let's plot the carriage rules:
```{r}
plot(pneumo.rules, measure = c("support", "confidence"), shading = "lift", jitter=0)
```
```{r}
plot(pneumo.rules[1:10], method="graph", engine = 'interactive')

plot(pneumo.rules[1:10], method= "paracoord", control=list(reorder=TRUE))
```
reference: [R and Data Mining](http://www.rdatamining.com/examples/association-rules)
there are other cool market basket analysis visualizations here: 
